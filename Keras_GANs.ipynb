{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (assuming this code is run on Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we8NAGfjPash",
        "outputId": "36524a31-605e-495a-cfa5-b04b3705937c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the working directory to the Deep Learning folder\n",
        "%cd /content/drive/MyDrive/Deep Learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9l__YPVPfwG",
        "outputId": "4d21b493-4dfd-487b-b7c9-2b3247f69420"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import zeros, ones, expand_dims, asarray\n",
        "from numpy.random import randn, randint\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Concatenate\n",
        "from keras.layers import LeakyReLU, Dropout, Embedding\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras import initializers\n",
        "from keras.initializers import RandomNormal\n",
        "import keras.optimizers\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "from numpy.random import randn, randint\n",
        "from numpy import ones, zeros\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "from math import sqrt"
      ],
      "metadata": {
        "id": "Fwd6Z1aGPR9p"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset directory\n",
        "DATA_DIR = './animefacedataset'"
      ],
      "metadata": {
        "id": "7PaXAgCe4EQ3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the desired size for the images (assuming square images)\n",
        "image_size = 64\n",
        "\n",
        "# Set the batch size for data loading\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "-4p4D9qs4Eyq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Define the transformation pipeline for the training dataset\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,          # Rescale pixel values to the range [0, 1]\n",
        ")\n"
      ],
      "metadata": {
        "id": "h1P5ZVZv4UO4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training dataset using flow_from_directory\n",
        "X_train = train_datagen.flow_from_directory(\n",
        "    DATA_DIR,                        # Path to the target directory\n",
        "    target_size=(image_size, image_size),  # Resize images to the specified dimensions\n",
        "    batch_size=batch_size,            # Number of samples per batch\n",
        "    class_mode='input',\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "YhroyHwd4PN3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08579d9c-78a6-4bb6-d4ab-a246277c9163"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 63565 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    # Generate random values from a standard normal distribution\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "\n",
        "    # Reshape the 1D array of random values to a 2D array\n",
        "    z_input = x_input.reshape(n_samples, latent_dim)\n",
        "\n",
        "    # Return the generated latent points\n",
        "    return z_input\n"
      ],
      "metadata": {
        "id": "rTKPNwaROJ-i"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate real samples from a data generator\n",
        "def generate_real_samples(X_train, n_samples):\n",
        "    # Obtain the next batch from the generator\n",
        "    X, _ = next(X_train)\n",
        "\n",
        "    # Randomly select 'n_samples' samples from the batch\n",
        "    ix = randint(0, X.shape[0], n_samples)\n",
        "    X = X[ix]\n",
        "\n",
        "    # Generate corresponding labels indicating real samples (ones)\n",
        "    y = ones((n_samples, 1))\n",
        "\n",
        "    # Return the real samples and their labels\n",
        "    return X, y\n",
        "\n",
        "# Function to generate fake samples using a generator model\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    # Generate latent points as input for the generator\n",
        "    z_input = generate_latent_points(latent_dim, n_samples)\n",
        "\n",
        "    # Generate fake images using the generator model\n",
        "    images = generator.predict(z_input)\n",
        "\n",
        "    # Generate corresponding labels indicating fake samples (zeros)\n",
        "    y = zeros((n_samples, 1))\n",
        "\n",
        "    # Return the fake samples and their labels\n",
        "    return images, y\n"
      ],
      "metadata": {
        "id": "yieeXHJ6V63k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
        "    # Generate fake samples using the generator model\n",
        "    _, X = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\n",
        "    # Rescale pixel values from the range [-1, 1] to [0, 1]\n",
        "    X = (X + 1) / 2.0\n",
        "\n",
        "    # Plot generated images in a 10x10 grid\n",
        "    for i in range(100):\n",
        "        pyplot.subplot(10, 10, 1 + i)\n",
        "        pyplot.axis('off')\n",
        "        pyplot.imshow(X[i, :, :, 0], cmap='gray_r')  # Display grayscale images\n",
        "\n",
        "    # Save the generator model at the current training step\n",
        "    filename2 = 'anime_faces_model_%04d.h5' % (step+1)\n",
        "    g_model.save(filename2)\n",
        "\n",
        "    # Print a message indicating that the model has been saved\n",
        "    print('>Saved: %s' % (filename2))\n"
      ],
      "metadata": {
        "id": "uXCVFnn6OLOp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_plot(examples, n_examples):\n",
        "    # Create a grid of subplots to display generated examples\n",
        "    for i in range(n_examples):\n",
        "        pyplot.subplot(sqrt(n_examples), sqrt(n_examples), 1 + i)\n",
        "\n",
        "        # Turn off axis labels\n",
        "        pyplot.axis('off')\n",
        "\n",
        "        # Display the grayscale image in the subplot\n",
        "        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "\n",
        "    # Show the plot with the generated examples\n",
        "    pyplot.show()\n"
      ],
      "metadata": {
        "id": "RIJID2BIOPio"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def define_discriminator(in_shape=(image_size, image_size, 3)):\n",
        "    # Define a sequential model for the discriminator\n",
        "    model = models.Sequential([\n",
        "        # Convolutional layer with 64 filters, 4x4 kernel, and stride of 2x2\n",
        "        layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=in_shape),\n",
        "        layers.BatchNormalization(),  # Batch normalization to normalize activations\n",
        "        layers.LeakyReLU(0.2),  # Leaky ReLU activation with a slope of 0.2\n",
        "\n",
        "        # Convolutional layer with 128 filters, 4x4 kernel, and stride of 2x2\n",
        "        layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(0.2),\n",
        "\n",
        "        # Convolutional layer with 256 filters, 4x4 kernel, and stride of 2x2\n",
        "        layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(0.2),\n",
        "\n",
        "        # Convolutional layer with 512 filters, 4x4 kernel, and stride of 2x2\n",
        "        layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(0.2),\n",
        "\n",
        "        # Convolutional layer with 1 filter, 4x4 kernel, and stride of 1x1\n",
        "        layers.Conv2D(1, (4, 4), strides=(1, 1), padding='valid'),\n",
        "        layers.Flatten(),  # Flatten the output to a 1D vector\n",
        "        layers.Activation('sigmoid')  # Sigmoid activation for binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile the discriminator with binary cross-entropy loss and Adam optimizer\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create an instance of the discriminator model\n",
        "discriminator = define_discriminator()\n",
        "\n",
        "# Display the summary of the discriminator model\n",
        "discriminator.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2JwFOC-ORGA",
        "outputId": "aaf2136a-5b5a-443c-b20b-b4d2a01a08eb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 64)        256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 256)         524544    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 8, 8, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 512)         2097664   \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 4, 4, 512)         2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 1, 1, 1)           8193      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1)                 0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2768577 (10.56 MB)\n",
            "Trainable params: 2766657 (10.55 MB)\n",
            "Non-trainable params: 1920 (7.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the size of the latent vector\n",
        "latent_size = 128\n",
        "\n",
        "# Define the generator model\n",
        "generator = models.Sequential([\n",
        "    layers.InputLayer(input_shape=(latent_size,)),  # Input layer for the latent vector\n",
        "    layers.Reshape((1, 1, latent_size)),  # Reshape the latent vector to a 4D tensor\n",
        "\n",
        "    # Transposed convolutional layer with 512 filters, 4x4 kernel, stride of 1x1, and no bias\n",
        "    layers.Conv2DTranspose(512, kernel_size=4, strides=1, padding='valid', use_bias=False),\n",
        "    layers.BatchNormalization(),  # Batch normalization to normalize activations\n",
        "    layers.ReLU(),  # ReLU activation\n",
        "\n",
        "    # Transposed convolutional layer with 256 filters, 4x4 kernel, stride of 2x2, and no bias\n",
        "    layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.ReLU(),\n",
        "\n",
        "    # Transposed convolutional layer with 128 filters, 4x4 kernel, stride of 2x2, and no bias\n",
        "    layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.ReLU(),\n",
        "\n",
        "    # Transposed convolutional layer with 64 filters, 4x4 kernel, stride of 2x2, and no bias\n",
        "    layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same', use_bias=False),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.ReLU(),\n",
        "\n",
        "    # Transposed convolutional layer with 3 filters (for RGB channels), 4x4 kernel, stride of 2x2, no bias, and tanh activation\n",
        "    layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', use_bias=False, activation='tanh')\n",
        "])\n",
        "\n",
        "# Display the summary of the generator model\n",
        "generator.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8OJIWHpOTQO",
        "outputId": "3b3cbe16-64c0-4c66-d242-b5a3553e1d0d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_1 (Reshape)         (None, 1, 1, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 4, 4, 512)         1048576   \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 4, 4, 512)         2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 8, 8, 256)         2097152   \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 8, 8, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 16, 16, 128)       524288    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 16, 16, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2D  (None, 32, 32, 64)        131072    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 32, 32, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2D  (None, 64, 64, 3)         3072      \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3808000 (14.53 MB)\n",
            "Trainable params: 3806080 (14.52 MB)\n",
            "Non-trainable params: 1920 (7.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def define_gan(g_model, d_model):\n",
        "    # Set the discriminator to be non-trainable during GAN training\n",
        "    d_model.trainable = False\n",
        "\n",
        "    # Connect the generator to the discriminator\n",
        "    gan_output = d_model(g_model.output)\n",
        "\n",
        "    # Create a GAN model with the same input as the generator and the output from the discriminator\n",
        "    model = Model(g_model.input, gan_output)\n",
        "\n",
        "    # Compile the GAN model with binary cross-entropy loss and Adam optimizer\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create an instance of the GAN model by connecting the generator and discriminator\n",
        "gan_model = define_gan(generator, discriminator)\n"
      ],
      "metadata": {
        "id": "UVoF2xu6OVRG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_train is a generator obtained from flow_from_directory\n",
        "\n",
        "def train(g_model, d_model, gan_model, X_train, latent_dim, n_epochs=125, n_batch=128):\n",
        "    # Calculate the number of batches per epoch\n",
        "    bat_per_epo = X_train.n // n_batch\n",
        "    # Calculate the total number of training steps\n",
        "    n_steps = bat_per_epo * n_epochs\n",
        "\n",
        "    # Training loop\n",
        "    for i in range(n_steps):\n",
        "        # Train the discriminator on real samples\n",
        "        X_real, y_real = generate_real_samples(X_train, n_batch)\n",
        "        d_loss_r, d_acc_r = d_model.train_on_batch(X_real, y_real)\n",
        "\n",
        "        # Train the discriminator on fake samples generated by the generator\n",
        "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_batch)\n",
        "        d_loss_f, d_acc_f = d_model.train_on_batch(X_fake, y_fake)\n",
        "\n",
        "        # Train the generator via the GAN model\n",
        "        z_input = generate_latent_points(latent_dim, n_batch)\n",
        "        y_gan = ones((n_batch, 1))\n",
        "        g_loss, g_acc = gan_model.train_on_batch(z_input, y_gan)\n",
        "\n",
        "        # Print the losses and accuracies for monitoring training progress\n",
        "        print('>%d, dr[%.3f,%.3f], df[%.3f,%.3f], g[%.3f,%.3f]' % (i+1, d_loss_r, d_acc_r, d_loss_f, d_acc_f, g_loss, g_acc))\n",
        "\n",
        "        # Periodically summarize and visualize the generated samples\n",
        "        if (i+1) % (bat_per_epo * 1) == 0:\n",
        "            summarize_performance(i, g_model, latent_dim)\n",
        "\n",
        "    # Return the trained generator model\n",
        "    return g_model\n"
      ],
      "metadata": {
        "id": "KbJJOCmKOWyQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2At72yjMNlg8",
        "outputId": "706b40e1-a7ab-498b-e91c-8fdd00d97d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 5ms/step\n",
            ">1, dr[1.121,0.203], df[2.033,0.023], g[0.714,0.000]\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            ">2, dr[0.000,1.000], df[0.042,1.000], g[0.690,0.695]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">3, dr[0.000,1.000], df[0.105,0.992], g[0.680,0.992]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">4, dr[0.000,1.000], df[0.014,1.000], g[0.676,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">5, dr[0.001,1.000], df[0.019,1.000], g[0.662,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">6, dr[0.001,1.000], df[0.028,1.000], g[0.660,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">7, dr[0.001,1.000], df[0.006,1.000], g[0.650,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">8, dr[0.001,1.000], df[0.015,1.000], g[0.638,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">9, dr[0.003,1.000], df[0.011,1.000], g[0.628,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">10, dr[0.001,1.000], df[0.010,1.000], g[0.618,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">11, dr[0.003,1.000], df[0.007,1.000], g[0.606,1.000]\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            ">12, dr[0.003,1.000], df[0.010,1.000], g[0.597,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">13, dr[0.022,1.000], df[0.005,1.000], g[0.582,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">14, dr[0.002,1.000], df[0.010,1.000], g[0.575,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">15, dr[0.001,1.000], df[0.002,1.000], g[0.561,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">16, dr[0.001,1.000], df[0.007,1.000], g[0.549,1.000]\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            ">17, dr[0.004,1.000], df[0.003,1.000], g[0.535,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">18, dr[0.001,1.000], df[0.005,1.000], g[0.523,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">19, dr[0.002,1.000], df[0.004,1.000], g[0.513,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">20, dr[0.002,1.000], df[0.004,1.000], g[0.500,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">21, dr[0.006,1.000], df[0.004,1.000], g[0.486,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">22, dr[0.003,1.000], df[0.003,1.000], g[0.473,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">23, dr[0.034,0.984], df[0.003,1.000], g[0.452,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">24, dr[0.001,1.000], df[0.003,1.000], g[0.434,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">25, dr[0.004,1.000], df[0.003,1.000], g[0.421,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">26, dr[0.002,1.000], df[0.001,1.000], g[0.402,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">27, dr[0.002,1.000], df[0.004,1.000], g[0.392,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">28, dr[0.002,1.000], df[0.001,1.000], g[0.377,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">29, dr[0.012,0.984], df[0.003,1.000], g[0.367,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">30, dr[0.001,1.000], df[0.002,1.000], g[0.355,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">31, dr[0.002,1.000], df[0.002,1.000], g[0.342,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">32, dr[0.001,1.000], df[0.002,1.000], g[0.328,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">33, dr[0.001,1.000], df[0.002,1.000], g[0.314,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">34, dr[0.001,1.000], df[0.001,1.000], g[0.300,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">35, dr[0.002,1.000], df[0.003,1.000], g[0.291,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">36, dr[0.001,1.000], df[0.001,1.000], g[0.276,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">37, dr[0.001,1.000], df[0.002,1.000], g[0.260,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">38, dr[0.001,1.000], df[0.001,1.000], g[0.245,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">39, dr[0.002,1.000], df[0.001,1.000], g[0.229,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">40, dr[0.000,1.000], df[0.001,1.000], g[0.213,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">41, dr[0.002,1.000], df[0.002,1.000], g[0.200,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">42, dr[0.001,1.000], df[0.001,1.000], g[0.188,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">43, dr[0.000,1.000], df[0.001,1.000], g[0.174,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">44, dr[0.001,1.000], df[0.001,1.000], g[0.162,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">45, dr[0.002,1.000], df[0.001,1.000], g[0.151,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">46, dr[0.002,1.000], df[0.001,1.000], g[0.140,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">47, dr[0.001,1.000], df[0.001,1.000], g[0.131,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">48, dr[0.000,1.000], df[0.001,1.000], g[0.119,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">49, dr[0.000,1.000], df[0.001,1.000], g[0.111,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">50, dr[0.001,1.000], df[0.001,1.000], g[0.102,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">51, dr[0.001,1.000], df[0.001,1.000], g[0.094,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">52, dr[0.001,1.000], df[0.001,1.000], g[0.085,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">53, dr[0.001,1.000], df[0.001,1.000], g[0.078,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">54, dr[0.000,1.000], df[0.001,1.000], g[0.072,1.000]\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            ">55, dr[0.001,1.000], df[0.001,1.000], g[0.066,1.000]\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            ">56, dr[0.001,1.000], df[0.001,1.000], g[0.060,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">57, dr[0.000,1.000], df[0.001,1.000], g[0.055,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">58, dr[0.000,1.000], df[0.001,1.000], g[0.049,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">59, dr[0.000,1.000], df[0.001,1.000], g[0.045,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">60, dr[0.001,1.000], df[0.001,1.000], g[0.041,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">61, dr[0.001,1.000], df[0.001,1.000], g[0.036,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">62, dr[0.001,1.000], df[0.000,1.000], g[0.033,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">63, dr[0.001,1.000], df[0.000,1.000], g[0.029,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">64, dr[0.001,1.000], df[0.000,1.000], g[0.027,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">65, dr[0.000,1.000], df[0.000,1.000], g[0.023,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">66, dr[0.000,1.000], df[0.000,1.000], g[0.021,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">67, dr[0.000,1.000], df[0.000,1.000], g[0.019,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">68, dr[0.001,1.000], df[0.000,1.000], g[0.016,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">69, dr[0.001,1.000], df[0.000,1.000], g[0.014,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">70, dr[0.001,1.000], df[0.000,1.000], g[0.013,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">71, dr[0.000,1.000], df[0.000,1.000], g[0.011,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">72, dr[0.001,1.000], df[0.000,1.000], g[0.010,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">73, dr[0.000,1.000], df[0.000,1.000], g[0.008,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">74, dr[0.000,1.000], df[0.000,1.000], g[0.008,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">75, dr[0.001,1.000], df[0.000,1.000], g[0.006,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">76, dr[0.000,1.000], df[0.000,1.000], g[0.006,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">77, dr[0.000,1.000], df[0.000,1.000], g[0.005,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">78, dr[0.000,1.000], df[0.000,1.000], g[0.004,1.000]\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            ">79, dr[0.000,1.000], df[0.000,1.000], g[0.004,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">80, dr[0.000,1.000], df[0.000,1.000], g[0.003,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">81, dr[0.000,1.000], df[0.000,1.000], g[0.003,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">82, dr[0.001,1.000], df[0.000,1.000], g[0.003,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">83, dr[0.000,1.000], df[0.000,1.000], g[0.002,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">84, dr[0.000,1.000], df[0.000,1.000], g[0.002,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">85, dr[0.000,1.000], df[0.000,1.000], g[0.002,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">86, dr[0.000,1.000], df[0.000,1.000], g[0.002,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">87, dr[0.000,1.000], df[0.000,1.000], g[0.001,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">88, dr[0.000,1.000], df[0.000,1.000], g[0.001,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">89, dr[0.000,1.000], df[0.000,1.000], g[0.001,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">90, dr[0.000,1.000], df[0.000,1.000], g[0.001,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">91, dr[0.000,1.000], df[0.000,1.000], g[0.001,1.000]\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            ">92, dr[0.000,1.000], df[0.000,1.000], g[0.001,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">93, dr[0.001,1.000], df[0.000,1.000], g[0.001,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">94, dr[0.000,1.000], df[0.000,1.000], g[0.001,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">95, dr[0.000,1.000], df[0.000,1.000], g[0.000,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">96, dr[0.000,1.000], df[0.000,1.000], g[0.000,1.000]\n",
            "4/4 [==============================] - 0s 8ms/step\n",
            ">97, dr[0.000,1.000], df[0.000,1.000], g[0.000,1.000]\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            ">98, dr[0.000,1.000], df[0.000,1.000], g[0.000,1.000]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            ">99, dr[0.000,1.000], df[0.000,1.000], g[0.000,1.000]\n"
          ]
        }
      ],
      "source": [
        "latent_dim = 128\n",
        "gan = train(generator, discriminator, gan_model, X_train, latent_dim, n_epochs=25, n_batch=128)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_examples = 9\n",
        "latent_points = generate_latent_points(latent_dim, n_examples)\n",
        "X  = gan.predict(latent_points)\n",
        "X = (X + 1) / 2.0\n",
        "save_plot(X, n_examples)"
      ],
      "metadata": {
        "id": "SXqRAVqUOhR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WBCeVPpCWtxX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}